"""
ANALIZADOR DE SENTIMIENTO - VERSI칍N FINAL COMPLETA
Para EvaBot - Por Frida
"""

class SentimentAnalyzer:
    def __init__(self):
        """Inicializa con todas las categor칤as de violencia de g칠nero"""
        self.patterns = {
            "control": [
                "no salgas con", "no hables con", "d칩nde est치s", 
                "con qui칠n est치s", "revisa tu celular", "celos",
                "controla", "vigila", "no te vistas as칤", "exige saber"
            ],
            "humillacion": [
                "eres una", "no sirves", "est치s loca", "nadie te quiere",
                "gorda", "fea", "in칰til", "dram치tica", "exagerada", "est칰pida"
            ],
            "amenazas": [
                "te voy a", "si no haces", "vas a ver", 
                "te arrepentir치s", "suicid", "matar", "da침ar",
                "golpear", "lastimar", "acabar contigo"
            ],
            "aislamiento": [
                "no veas a tu familia", "tus amigas son", 
                "no conf칤es en", "solo te tengo a m칤", "no salgas sin m칤"
            ],
            "violencia_economica": [
                "no te doy dinero", "me das tu sueldo", 
                "no trabajes", "dependes de m칤", "controlo el dinero"
            ]
        }
        
        # Sistema de palabras clave para determinar gravedad
        self.severity_keywords = {
            "leve": ["celos", "molesto", "enojado"],
            "moderado": ["amenaza", "humillaci칩n", "control", "obligar"],
            "alto": ["matar", "suicidio", "golpear", "da침ar", "lastimar"]
        }
    
    def analyze_text(self, text):
        """Analiza texto y detecta violencia con sistema completo"""
        if not text:
            return self._empty_analysis()
        
        text_lower = text.lower().strip()
        
        # Detectar patrones de violencia
        detected_patterns = self._detect_patterns(text_lower)
        
        # Calcular nivel de severidad
        severity_level = self._calculate_severity(text_lower, detected_patterns)
        
        # Generar respuesta autom치tica
        response = self._generate_response(severity_level)
        
        return {
            "texto_analizado": text,
            "patrones_detectados": detected_patterns,
            "nivel_riesgo": severity_level,
            "respuesta_recomendada": response,
            "riesgo_detectado": len(detected_patterns) > 0
        }
    
    def _detect_patterns(self, text):
        """Busca patrones de violencia en el texto"""
        detected = {}
        
        for category, patterns in self.patterns.items():
            matches_found = []
            for pattern in patterns:
                if pattern in text:
                    matches_found.append(pattern)
            
            if matches_found:
                detected[category] = matches_found
        
        return detected
    
    def _calculate_severity(self, text, patterns):
        """Calcula nivel de severidad basado en patrones detectados"""
        if not patterns:
            return "ninguno"
        
        # Si detectamos amenazas, es ALTO RIESGO
        if "amenazas" in patterns:
            return "alto"
        
        # Si detectamos palabras de alto riesgo
        for severe_word in self.severity_keywords["alto"]:
            if severe_word in text:
                return "alto"
        
        # Si hay m칰ltiples tipos de violencia, es MODERADO
        if len(patterns) >= 2:
            return "moderado"
        
        # Un solo tipo de violencia es LEVE
        return "leve"
    
    def _generate_response(self, severity):
        """Genera respuesta autom치tica seg칰n el nivel de riesgo"""
        responses = {
            "ninguno": "No detect칠 indicios claros de violencia. Estoy aqu칤 para escucharte 游눞",
            "leve": "He detectado algunos patrones de control. 쯈uieres contarme m치s sobre esta situaci칩n?",
            "moderado": "丘멆잺 He detectado comportamientos preocupantes. Esto podr칤a ser violencia psicol칩gica. 쮼st치s a salvo?",
            "alto": "游 춰ALTO RIESGO DETECTADO! 游 Por favor, contacta a: L칤nea 144 (violencia de g칠nero) o 911 (emergencias). Tu seguridad es lo m치s importante."
        }
        
        return responses.get(severity, responses["ninguno"])
    
    def _empty_analysis(self):
        """Manejo de texto vac칤o o inv치lido"""
        return {
            "texto_analizado": "",
            "patrones_detectados": {},
            "nivel_riesgo": "ninguno",
            "respuesta_recomendada": "No pude analizar el mensaje. 쯇odr칤as intentarlo de nuevo?",
            "riesgo_detectado": False
        }


def analyze_sentiment(text):
    """Funci칩n simple para an치lisis r치pido desde otras partes del c칩digo"""
    analyzer = SentimentAnalyzer()
    return analyzer.analyze_text(text)


# Pruebas completas del sistema
if __name__ == "__main__":
    print("游댌 PROBANDO VERSI칍N FINAL DEL ANALIZADOR")
    print("=" * 50)
    
    test_messages = [
        "Mi novio revisa mi celular y no me deja ver a mis amigas",
        "Hoy tuve un d칤a maravilloso!",
        "Me dijo que si lo dejaba se iba a suicidar",
        "Siempre me dice que no sirvo para nada y que soy una in칰til",
        "Controla todo mi dinero y no me deja trabajar"
    ]
    
    for message in test_messages:
        print(f"\n游닏 Mensaje: '{message}'")
        result = analyze_sentiment(message)
        print(f"   游꿢 Riesgo: {result['nivel_riesgo']}")
        print(f"   游늵 Patrones: {result['patrones_detectados']}")
        print(f"   游눫 Respuesta: {result['respuesta_recomendada']}")
        print("   " + "-" * 40)