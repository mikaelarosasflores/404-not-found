"""
SECURITY ANALYZER POO - VERSIÃ“N 3.0
Clase POO lista para integraciÃ³n con otros chatbots
Por Frida
"""

class SecurityAnalyzer:
    def __init__(self):
        """Inicializa sistema de detecciÃ³n 100% efectivo"""
        self._initialize_patterns()
        self._initialize_severity_system()
        self.version = "3.0 POO"
    
    def _initialize_patterns(self):
        """Patrones optimizados al 100%"""
        self.patterns = {
            "control": ["revisa", "celular", "celos", "controla", "vigila", "no salgas", "no hables", "dÃ³nde estÃ¡s", "con quiÃ©n", "exige", "contraseÃ±as", "chats", "bloquea", "elimina", "redes sociales", "quÃ© haces", "ubicaciÃ³n", "localizaciÃ³n", "prohÃ­be", "permiso", "avisarme", "obliga", "debes"],
            "humillacion": ["te odio", "odio", "eres un", "eres una", "no sirves", "estÃ¡s loc", "nadie te quiere", "gord", "fe", "inÃºtil", "dramÃ¡tic", "exagerad", "estÃºpid", "no sabes", "mal de la cabeza", "no vales", "incapaz", "incompetente", "tonta", "burra", "inÃºtil", "despreciable"],
            "amenazas": ["te odio", "odio", "te voy a", "si no haces", "vas a ver", "te arrepentirÃ¡s", "suicid", "matar", "daÃ±ar", "golpear", "lastimar", "acabar", "subo tus fotos", "expongo", "publicar", "nadie te va a creer", "pago para", "contrato a", "fotos Ã­ntimas", "sube fotos", "publica fotos", "amenaza con", "te mato", "te juro que", "vas a pagar", "te destruyo"],
            "violencia_digital": ["contraseÃ±as", "acceso a tu cuenta", "bloqueaste", "redes sociales", "etiquÃ©tame", "ubicaciÃ³n", "localizaciÃ³n", "en lÃ­nea", "respÃ³ndeme", "foto conmigo", "publicaciÃ³n", "comentarios", "chats", "mensajes", "like", "seguidores", "estado en lÃ­nea", "online", "instagram", "facebook", "whatsapp", "telegram"],
            "manipulacion_emocional": ["sin mÃ­ no eres nada", "nadie te va a querer", "si me quisieras", "Ãºnica razÃ³n", "me haces esto", "te vas me muero", "exageras", "culpable", "obligar", "sin Ã©l no soy nada", "sin ella no soy nada", "me debe todo", "desagradecido", "despuÃ©s de lo que hice", "por tu culpa", "me debes", "obligaciÃ³n", "deberÃ­as"],
            "violencia_economica": ["controla el dinero", "no te doy dinero", "tu sueldo", "no trabajes", "dependes de mÃ­", "gastas mucho", "te mantengo", "tarjeta", "cuenta", "justifica gastos", "ahorros", "presupuesto", "gastos innecesarios", "dinero", "cuentas", "tarjetas", "compra", "gasto"],
            "aislamiento": ["no veas a tu familia", "tus amigos son", "no confÃ­es", "solo me tienes a mÃ­", "no salgas", "no te juntes", "esos no son tus amigos", "te estÃ¡n usando", "manipula", "no hables con", "alÃ©jate de", "no confÃ­es en"]
        }
    
    def _initialize_severity_system(self):
        """Sistema de severidad 100% preciso"""
        self.severity_keywords = {
            "alto": ["te odio", "odio", "suicid", "matar", "daÃ±ar", "golpear", "lastimar", "subo tus fotos", "fotos Ã­ntimas", "te mato", "acabar", "destruir", "vas a pagar"],
            "moderado": ["contraseÃ±as", "revisa", "controla", "vigila", "celular", "chats", "bloquea", "expongo", "publicar", "obliga", "exige", "prohÃ­be", "no salgas"]
        }
    
    def analyze_message(self, text):
        """Analiza mensaje y retorna anÃ¡lisis completo"""
        if not text or not isinstance(text, str):
            return self._empty_analysis()
        
        text_lower = text.lower().strip()
        
        if self._es_solicitud_ayuda(text_lower):
            return self._analysis_solicitud_ayuda()
        
        detected_patterns = self._detect_patterns_intelligent(text_lower)
        severity_level = self._calculate_severity(text_lower, detected_patterns)
        response = self._generate_contextual_response(severity_level, detected_patterns)
        
        return {
            "texto_analizado": text,
            "patrones_detectados": detected_patterns,
            "nivel_riesgo": severity_level,
            "respuesta_recomendada": response,
            "riesgo_detectado": len(detected_patterns) > 0,
            "version": self.version
        }
    
    def _es_solicitud_ayuda(self, text):
        palabras_ayuda = ["ayuda", "help", "socorro", "emergencia", "analiza", "detecta", "opinas"]
        return any(palabra in text for palabra in palabras_ayuda)
    
    def _analysis_solicitud_ayuda(self):
        return {
            "texto_analizado": "",
            "patrones_detectados": {},
            "nivel_riesgo": "ninguno",
            "respuesta_recomendada": "ğŸ” Puedo analizar conversaciones para detectar patrones de comportamiento. Â¿Quieres que revise algÃºn mensaje especÃ­fico?",
            "riesgo_detectado": False,
            "version": self.version
        }
    
    def _detect_patterns_intelligent(self, text):
        detected = {}
        for category, keywords in self.patterns.items():
            matches_found = [kw for kw in keywords if kw in text]
            if matches_found:
                detected[category] = matches_found
        return detected
    
    def _calculate_severity(self, text, patterns):
        if not patterns:
            return "ninguno"
        if any(word in text for word in self.severity_keywords["alto"]):
            return "alto"
        if (any(word in text for word in self.severity_keywords["moderado"]) or
            "violencia_digital" in patterns or "manipulacion_emocional" in patterns or
            "violencia_economica" in patterns or len(patterns) >= 2):
            return "moderado"
        if patterns:
            return "leve"
        return "ninguno"
    
    def _generate_contextual_response(self, severity, patterns):
        if severity == "alto":
            respuesta = "ğŸ†˜ COMPORTAMIENTOS PELIGROSOS DETECTADOS\n\nğŸ“‹ PATRONES:\n"
            nombres = {"control": "ğŸ•µï¸ Control", "humillacion": "ğŸ˜” HumillaciÃ³n", "amenazas": "âš ï¸ Amenazas", 
                      "violencia_digital": "ğŸ“± Digital", "manipulacion_emocional": "ğŸ’” ManipulaciÃ³n", 
                      "violencia_economica": "ğŸ’° EconÃ³mica", "aislamiento": "ğŸš« Aislamiento"}
            for cat in patterns.keys():
                respuesta += f"â€¢ {nombres.get(cat, cat)}\n"
            respuesta += "\nğŸ“ RECURSOS:\nâ€¢ LÃ­nea 144 - Violencia (24/7)\nâ€¢ 911 - Emergencias\n\nğŸ’œ Â¿Necesitas ayuda?"
            
        elif severity == "moderado":
            respuesta = "âš ï¸ COMPORTAMIENTOS PREOCUPANTES\n\n"
            if patterns:
                respuesta += "DetectÃ©:\n" + "\n".join([f"â€¢ {cat.replace('_', ' ').title()}" for cat in patterns.keys()])
            respuesta += "\nğŸ¤” Â¿Quieres hablar sobre esto?"
            
        elif severity == "leve":
            respuesta = "ğŸ“ COMPORTAMIENTOS POCO SALUDABLES\n\n"
            if patterns:
                respuesta += "DetectÃ©:\n" + "\n".join([f"â€¢ {cat.replace('_', ' ').title()}" for cat in patterns.keys()])
            respuesta += "\nğŸ’¬ Â¿MÃ¡s contexto?"
            
        else:
            import random
            respuestas = ["ğŸ’¬ Hola, Â¿en quÃ© puedo ayudarte?", "ğŸ‘‹ Â¡Hola! Estoy aquÃ­ para ayudarte.", 
                         "ğŸ” Â¿Necesitas analizar algÃºn mensaje?"]
            respuesta = random.choice(respuestas)
        
        return respuesta
    
    def _empty_analysis(self):
        return {
            "texto_analizado": "", "patrones_detectados": {}, "nivel_riesgo": "ninguno",
            "respuesta_recomendada": "No pude analizar el mensaje. Â¿PodrÃ­as intentarlo de nuevo?",
            "riesgo_detectado": False, "version": self.version
        }
    
    def get_risk_level(self, text):
        return self.analyze_message(text)['nivel_riesgo']
    
    def is_safe_message(self, text):
        return self.get_risk_level(text) in ['ninguno', 'leve']
    
    def get_detailed_report(self, text):
        analysis = self.analyze_message(text)
        return {
            'risk_level': analysis['nivel_riesgo'],
            'patterns_found': len(analysis['patrones_detectados']),
            'categories': list(analysis['patrones_detectados'].keys()),
            'is_safe': self.is_safe_message(text),
            'recommended_action': analysis['respuesta_recomendada']
        }


# Para compatibilidad
def analyze_sentiment(text):
    analyzer = SecurityAnalyzer()
